[IL2233VT24_Lecture_6_slides](IL2233VT24_Lecture_6_slides.pdf)
Let's see an example to motivate the use of #NN in this field.

The #fibonaci-series is a #time-series and we want to do a model for it.$$F_{t}= F_{t-1}+F_{t-2}$$ This is the model we use.
# 1. Neural networks
A **neural network** is according to Dr Robert Hecht-Nielsen, a *computing system made up of a number of simple, highly interconnected processing elements, which process information by their dynamic state response to external inputs*.

The idea of #ANN is based on the belief that working principle of human brain by making the right connections, can be imitated using silicon and wires as living neurons and dendrites.

An ANN is based on a collection of connected units or nodes called artificial neurons which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal from one artificial neuron to another.

**An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it.**![](Pasted%20image%2020240415154730.png)
# 2. Perceptron and MLP
The #perceptron is a mathematical/conceptual model of a biological neuron.

A **nonlinear function** is **essential to model arbitrarily complex functionality** which is **not achievable by linear combinations of any depth**.![](Pasted%20image%2020240415154809.png)Since the **learning strategy requires** *computation of the gradient of the error function* **at each iteration step**, we must *guarantee the continuity and differentiability* of the #error-function. 

We have to use a kind of activation function other than the step function used in perceptrons, because the **composite function produced by interconnected perceptrons is discontinuous**, and **therefore** the **error function too**. 

One of the more popular activation functions for #backpropagation networks is the #sigmoid.

The **logistic sigmoid function**:$$S_{c}(x)=\frac{1}{1+e^{-cx}}$$with $c$ a constant that can be selected arbitrarily and its reciprocal $1/c$ is called the **temperature parameter** in stochastic neural network.![](Pasted%20image%2020240415161629.png)
Higher values of $c$ bring the shape of the sigmoid closer to that of the step function and in the limit to $\infty$ it converges to a step function at the origin.![](Pasted%20image%2020240415161639.png)
An **artificial neuron** mimics the working of a biophysical neuron, but is not a biological neuron model.

An **Artificial neuron network** #ANN is a composition of simple elements called artificial neurons, which receive input, perform simple calculation and produce outputs.
## MLP
A **Multi-Layer Perceptron** #MLP  contains one or more hidden layers, apart from one input and one output layer.

The input layer has no weights associated, it should not be considered as a network layer. For convenience, many people still call it input layer.

An #MLP is a feed-forward network without feedback connections.![](Pasted%20image%2020240415162457.png)
**Neural networks** are said to be **universal** **function approximators**:
- #MLP are universal function approximators as shown by Cybenko’s theorem. 
- For example, a two-layer network with linear outputs can uniformly approximate any continuous function on a compact input domain to arbitrary accuracy, provided the network has a sufficiently large number of hidden units.
- By the theorem, #MLP **with one hidden layer is enough to represent (not learn) an approximation of any function to an arbitrary degree of accuracy**.
- Even if MLP is able to represent an arbitrary function, learning can fail for two reasons.
	- The optimization algorithm may fail to find the value of the parameters for the desired function. 
	- The training algorithm might choose the wrong function as a result of overfitting.

Why going deeper for #DNN?
- Because shallow net may need larger width, may overfit more, on the other hand
- Going deeper gives more opportunities
# 3. Neural network training
![](Pasted%20image%2020240415163557.png)
#ANN #training is a #supervised-learning.

Given a set of features $X=(X_{1},X_{2},\dots)$ and a target $Y$, an #ANN can learn the relationship between the features and the target.

#Training: Given an #ANN architecture, the goal of training/learning is to **assign correct weights to the connections between layers so that the error is minimized**.

#Inference: *Once the training terminates*, the **"learned” ANN is ready for inference or prediction,**.
	i.e., Given an input vector, these weights determine what the output vector of the ANN is.

## Training process
#ANN training is typically an error-based supervised learning – ”learning from mistakes”. 
- **Initialization**: Initially all the connection weights of the ANN are randomly assigned. 
	- **Forward pass:** For every input in the training dataset, the ANN is activated and its output is computed.
	- **Backward pass:** This output is compared with the desired output that we already know, and the error or loss is “propagated” back to the previous layer. – Error back propagation 
	- **Weight update:** This error is noted and the weights are “adjusted” accordingly. – Optimization 
- **Iteration**: This process is repeated until the output error is below a predetermined threshold or a stopping criterion reached.
![](Pasted%20image%2020240415164330.png)
## Error/loss function
For **regression problems**, a standard error function is the sum of squares error function.

For each training sample $n$, the error is defined as$$E_{n}=\frac{1}{2}\sum_{k=1}^{K}(y_{k}-t_{k})^{2}$$where $y_{k}$ is the forward calculation result, $t_{k}$ is the target result.

The #error-function for a set of *independent observation* comprise a sum of terms, one for each data point $n$:$$E(w)=\sum_{n=1}^{N}E_{n}(w)$$
## Weight optimisation
The combination of weights which minimizes the error function is considered to be a solution of the learning problem. 
- Learning objective: Minimize the error (E) as a function of all weights $w_i$ 
- Learning strategy: #Gradient-descent $$w_i = w_i − η \frac{∂E}{∂w_{i}}$$where $\eta>0$ is the learning rate.

Note that the error function is defined with respect to a *training set*, and so each step requires that the entire training set be processed in order to evaluate the error gradient.
### Stochastic Gradient Descent
**Stochastic Gradient Descent** #SGD, known as sequential or non-line gradient descent, updates the weight vector based on one data point at a time$$w^{t+1}=w^{t}-\eta \cdot E_{n}(w^{t})$$This update is repeated by cycling though the data either *in sequence* or *by selecting points at random with replacement*.

It **handles redundancy** in the data much more efficiently.
## Back-propagation and SGD
- #Error Back-propagation 
	- An efficient method of computing gradients in directed graphs of computations, such as neural networks. 
	- It is a simple implementation of chain rule of derivatives, which allows to compute all partial derivatives in linear time in terms of the graph size. 
- #SGD 
	- It is an optimization method using the gradient information to update weights. 
	- It is one of many known optimization techniques which use gradient information such as RMSProp (Root Mean Square Propagation) and Adam (Adaptive Moment Estimation) etc.
# 4. ANN for time series prediction
