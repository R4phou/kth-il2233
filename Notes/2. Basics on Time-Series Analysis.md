[IL2233VT24_Lecture_2_slides](IL2233VT24_Lecture_2_slides.pdf)
# 1. Exploratory Data Analysis #EDA
In statistics #EDA is an approach of analyzing data sets to summarize their main characteristics, often using graphics and other data visualisation methods.

There are multiple types of plots for time series:
- Line plot
- Histogram and density plot
- Box & Whisker plot
- Heat map
- Lag scatter plot
- Auto-Correlation function #ACF plot
- Partial Auto-Correlation function #PACF plot

The focus is on uni-variate #time-series,but the techniques are also applicable on multivariate time series (more than one observation at each time step).

It is useful to explore the **temporal structure** of time series with #line-plot, #lag-plot and #AC-plot. 

Or to understand the **distribution of observations** using #histogram and #density-plot.

We can also capture the **change in distribution over intervals** using #box-plot and #heat-map plots.

Plots of the raw sample data can provide valuable diagnostics to *identify temporal structures like trends, cycles, and seasonality that can* **influence the choice of model**.
# 2. Data visualisation
![IL2233VT24_Lecture_2_slides](IL2233VT24_Lecture_2_slides.pdf#page=7)

Some interesting facts about #lag-plot:
- A #lag is a fixed amount of passing time. The $k$-th lag is the time period that happened "k" time points before time $t$.
- For example: $Lag_{4}(Y_{9})=Y_{5}$
-  A #lag1-plot has $Y_{t}$ for all $t$ on the vertical axis. And $Y_{t-1}$ for all $t$ on the horizontal axis.

The #auto-covariance and #autocorrelation measure the **linear relationship** between lagged values of a time series $y$. 
![IL2233VT24_Lecture_2_slides](IL2233VT24_Lecture_2_slides.pdf#page=24)
#ACF measure the linear relationship between $y_{t}$ and $y_{t-k}$.
#PACF measures the linear relationship between $y_{t}$ and $y_{t-k}$ when the inferences (effects) of other time lags are removed. *IT IS THUS BETTER TO USE THIS ONE TO SEE THE RELATIONS*.
# 3. Application of EDA
#EDA is used to check for:
- #outliers: line plot
- #randomness: lag plot
- #modeling-suitability: #stationary$\to$ #ADF or line plot/trend
- #seasonality: decomposition #STL
- #autocorrelation: #ACF and #PACF
# 4. White noise and Randomness
A #WN white noise series is a **stochastic random process**, with each stochastic variable is #iid (independently and identically distributed). 

It plays a special role in time-series analysis:
- For **predictability**: a #WN series has no dependent structure in data and thus nothing is predictable.
- For **model validity**: the #residual-series of a time-series model should be white noise.
![](Pasted%20image%2020240410144137.png)
The starting point for time-series analysis is that the time series is not a white noise series.
## Stationarity of a series
The **Augmented Dickey Fuller Test** #ADF is used to determine whether a series is stationary or not:
- if the $pvalue < 0.05$, we reject the null hypothesis and thus the series is #stationary. 

Another way to check if a series is #stationary is to look at the #lag-plot and see if we recognize some sort of pattern.

A #WN is #stationary. 
## Randomness of a series
To check whether a series is #random or not, we can se the **Ljung-Box test** #Ljung-Box.

It is a statistical hypothesis test that checks if auto-correlations are significantly away from zero in a time series. It is often used to test if the residual series after prediction is random noise.![](Pasted%20image%2020240410144602.png)
Can be used in python `import stasmodels.api as sm; sm.stats.acorr_ljungbox()`.

If the $pvalue > 0.05$, then we accept the Null hypothesis that the series is independent, meaning that the series is random.
